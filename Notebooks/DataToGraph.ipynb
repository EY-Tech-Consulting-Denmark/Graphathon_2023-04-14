{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87b59a0",
   "metadata": {},
   "source": [
    "# Notebook for Loading in the Database and Creating a Graph\n",
    "\n",
    "Start by importing the libraries and connecting to the neo4j sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7efb69-de57-4efb-9bf7-0770354958ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from graphdatascience import GraphDataScience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to neo4j DBMS\n",
    "\n",
    "#this is local DBMS via neo4j Desktop for testing purposes needs to be changed\n",
    "DB_ULR = \"bolt://localhost:7687\" \n",
    "DB_USER = \"neo4j\"\n",
    "DB_PASS = \"1234\"\n",
    "gds = GraphDataScience(DB_ULR, auth=(DB_USER, DB_PASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694de76-4d50-4bb5-92b6-e3ac52a2a909",
   "metadata": {},
   "source": [
    "## Loading data into the graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8f01b46-5489-42cb-9442-1c7cd96bc257",
   "metadata": {},
   "source": [
    "Preprocessed data stored in https://github.com/EY-Tech-Consulting-Denmark/Graphathon_2023-04-14/tree/main/Data/clean_data can be loaded into a Neo4j sandbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d36247-291d-41be-837c-3a16c79b1803",
   "metadata": {},
   "source": [
    "### Loading the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71d660-883f-4180-ab77-8abab6c1c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/EY-Tech-Consulting-Denmark/Graphathon_2023-04-14/main/Data/clean_data/data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fe304",
   "metadata": {},
   "source": [
    "## Create the nodes in the graph\n",
    "Start with creating beneficiary nodes and attaching the chronic conditions they have as relationships (includes renal disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d6dfb3-0826-4daa-a0a5-3686bffede5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Condition nodes \n",
    "gds.run_cypher('create constraint if not exists for (n:Condition) require (n.id) is node key')\n",
    "gds.run_cypher('''\n",
    "    unwind [\n",
    "        'RenalDiseaseIndicator',\n",
    "        'ChronicCond_Alzheimer', 'ChronicCond_Heartfailure',\n",
    "        'ChronicCond_KidneyDisease', 'ChronicCond_Cancer',\n",
    "        'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression',\n",
    "        'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart',\n",
    "        'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n",
    "        'ChronicCond_stroke'\n",
    "    ] as conditionId\n",
    "    merge (n:Condition{id: conditionId})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Beneficiary nodes and connect them with HAS_CONDITION relationships to their corrosponding chronic conditions\n",
    "gds.run_cypher('create constraint if not exists for (n:Beneficiary) require (n.id) is node key')\n",
    "gds.run_cypher('''\n",
    "    match (c:Condition)\n",
    "    with collect(c) as conditions\n",
    "    unwind $data as row\n",
    "    merge (n:Beneficiary{id: row.BeneID})\n",
    "        set n.dob = date(row.DOB),\n",
    "            n.gender = row.Gender,\n",
    "            n.race = row.Race,\n",
    "            n.age = row.Age,\n",
    "            n.state = row.State,\n",
    "            n.county = row.County\n",
    "    with conditions, n, row\n",
    "    call {\n",
    "        with row, conditions, n\n",
    "        foreach(\n",
    "            c in [x in conditions where row[x.id] = 1 or row[x.id] = 'Y' | x] |\n",
    "            merge (n)-[:HAS_CONDITION]->(c)\n",
    "        )\n",
    "    }\n",
    "''', params = {'data': data.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add date of death (DOD) to beneficiaries who have passed away\n",
    "\n",
    "dead = data[['BeneID','DOD']].dropna()\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (n:Beneficiary{id: row.BeneID})\n",
    "        set n.dod = date(row.DOD)\n",
    "''', params = {'data': dead.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Provider nodes\n",
    "\n",
    "gds.run_cypher('create constraint if not exists for (n:Provider) require (n.id) is node key')\n",
    "label_dist = gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    merge (n:Provider{id: row.Provider})\n",
    "        set n.fraud = case row.PotentialFraud when 1 then true else false end\n",
    "    return n.fraud as is_fraud, count(*) as count\n",
    "''', params = {'data': data.to_dict('records')})\n",
    "label_dist.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d2b87",
   "metadata": {},
   "source": [
    "### Create Claims Data\n",
    "\n",
    "Going to create a node for each Claim, Provider, Physician, Diagnosis, and Procedure code. Create the relationships between beneficiary and their claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create claims data\n",
    "\n",
    "# Create constraints on our new node labels\n",
    "gds.run_cypher('create constraint if not exists for (n:Claim) require (n.id) is node key')\n",
    "gds.run_cypher('create constraint if not exists for (n:Provider) require (n.id) is node key')\n",
    "gds.run_cypher('create constraint if not exists for (n:Physician) require (n.id) is node key')\n",
    "gds.run_cypher('create constraint if not exists for (n:Diagnosis) require (n.id) is node key')\n",
    "gds.run_cypher('create constraint if not exists for (n:Procedure) require (n.id) is node key')\n",
    "\n",
    "claims_cypher = '''\n",
    "    unwind $data as row\n",
    "    merge (c:Claim{id: row.ClaimID})\n",
    "        set c.startDate = date(row.ClaimStartDt),\n",
    "            c.endDate = date(row.ClaimEndDt),\n",
    "            c.admissionDate = date(row.AdmissionDt),\n",
    "            c.dischargeDate = date(row.DischargeDt),\n",
    "            c.deductibleAmt = row.DeductibleAmtPaid,\n",
    "            c.reimbursedAmt = row.InscClaimAmtReimbursed,\n",
    "            c.daysAdmitted = row.DaysAdmitted,\n",
    "            c.daysClaimLasted = row.DaysClaimLasted,\n",
    "            c.claimEndAfterDischarged = row.ClaimEndAfterDischarged \n",
    "    merge (p:Provider{id: row.Provider})\n",
    "    merge (c)-[:SUBMITTED_BY]->(p)                       \n",
    "    merge (b:Beneficiary{id: row.BeneID})\n",
    "    merge (c)-[:CREATED_FOR]->(b)                     \n",
    "    '''\n",
    "\n",
    "gds.run_cypher(claims_cypher, params = {'data': data.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b848c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Diagnoses code nodes and create the relationship ADMIT_DIAGNOSIS\n",
    "\n",
    "gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    match (c:Claim)\n",
    "    where c.id = row.ClaimID\n",
    "    merge (d:Diagnosis{id: row.ClmAdmitDiagnosisCode})\n",
    "    merge (c)-[:HAS_ADMISSION_WITH]->(d)                    \n",
    "''', params = {'data': data.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b60b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Diagnoses code nodes and create the relationship ADMIT_DIAGNOSIS\n",
    "\n",
    "gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    match (c:Claim)\n",
    "    where c.id = row.ClaimID\n",
    "    merge (d:Diagnosis{id: row.DiagnosisGroupCode})\n",
    "    merge (c)-[:HAS_GROUP_CODE_OF]->(d)                        \n",
    "''', params = {'data': data.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef09ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the relationships between claims and claim diagnoses codes\n",
    "\n",
    "gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    match (c:Claim)\n",
    "    where c.id = row.ClaimID\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_1})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                            \n",
    "''', params = {'data': data.to_dict('records')})\n",
    "\n",
    "claim_code_2 = data[['ClaimID','ClmDiagnosisCode_2']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_2})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                             \n",
    "''', params = {'data': claim_code_2.to_dict('records')})\n",
    "\n",
    "claim_code_3 = data[['ClaimID','ClmDiagnosisCode_3']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_3})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                    \n",
    "''', params = {'data': claim_code_3.to_dict('records')})\n",
    "\n",
    "claim_code_4 = data[['ClaimID','ClmDiagnosisCode_4']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_4})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                      \n",
    "''', params = {'data': claim_code_4.to_dict('records')})\n",
    "\n",
    "claim_code_5 = data[['ClaimID','ClmDiagnosisCode_5']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_5}) \n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                     \n",
    "''', params = {'data': claim_code_5.to_dict('records')})\n",
    "\n",
    "claim_code_6 = data[['ClaimID','ClmDiagnosisCode_6']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_6})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                         \n",
    "''', params = {'data': claim_code_6.to_dict('records')})\n",
    "\n",
    "claim_code_7 = data[['ClaimID','ClmDiagnosisCode_7']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_7})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                          \n",
    "''', params = {'data': claim_code_7.to_dict('records')})\n",
    "\n",
    "claim_code_8 = data[['ClaimID','ClmDiagnosisCode_8']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_8})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                           \n",
    "''', params = {'data': claim_code_8.to_dict('records')})\n",
    "\n",
    "claim_code_9 = data[['ClaimID','ClmDiagnosisCode_9']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_9})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                             \n",
    "''', params = {'data': claim_code_9.to_dict('records')})\n",
    "\n",
    "claim_code_10 = data[['ClaimID','ClmDiagnosisCode_10']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Diagnosis{id: row.ClmDiagnosisCode_10})\n",
    "    merge (c)-[:HAS_DIAGNOSIS_CODE_OF]->(d)                                                \n",
    "''', params = {'data': claim_code_10.to_dict('records')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b09d7",
   "metadata": {},
   "source": [
    "### Add Procedure nodes and connect them with the claim nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d07171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the relationships between claims and procedure codes\n",
    "\n",
    "procedure_code_1 = data[['ClaimID','ClmProcedureCode_1']].dropna()\n",
    "\n",
    "gds.run_cypher('''\n",
    "    unwind $data as row\n",
    "    match (c:Claim)\n",
    "    where c.id = row.ClaimID\n",
    "    merge (d:Procedure{id: row.ClmProcedureCode_1}) \n",
    "    merge (c)-[:HAS_PROCEDURE_CODE_OF]->(d)\n",
    "''', params = {'data': procedure_code_1.to_dict('records')})\n",
    "\n",
    "procedure_code_2 = data[['ClaimID','ClmProcedureCode_2']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Procedure{id: row.ClmProcedureCode_2})\n",
    "    merge (c)-[:HAS_PROCEDURE_CODE_OF]->(d)\n",
    "''', params = {'data': procedure_code_2.to_dict('records')})\n",
    "\n",
    "procedure_code_3 = data[['ClaimID','ClmProcedureCode_3']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Procedure{id: row.ClmProcedureCode_3})\n",
    "    merge (c)-[:HAS_PROCEDURE_CODE_OF]->(d)\n",
    "''', params = {'data': procedure_code_3.to_dict('records')})\n",
    "\n",
    "procedure_code_4 = data[['ClaimID','ClmProcedureCode_4']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Procedure{id: row.ClmProcedureCode_4})\n",
    "    merge (c)-[:HAS_PROCEDURE_CODE_OF]->(d)\n",
    "''', params = {'data': procedure_code_4.to_dict('records')})\n",
    "\n",
    "procedure_code_5 = data[['ClaimID','ClmProcedureCode_5']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (c:Claim{id: row.ClaimID})\n",
    "    merge (d:Procedure{id: row.ClmProcedureCode_5})\n",
    "    merge (c)-[:HAS_PROCEDURE_CODE_OF]->(d)\n",
    "''', params = {'data': procedure_code_5.to_dict('records')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2b0fd",
   "metadata": {},
   "source": [
    "### Add the Physician nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f15534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Physicians and their realtionship to the claim\n",
    "\n",
    "# Add attending physicians\n",
    "attend = data[['ClaimID','AttendingPhysician']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (n:Claim{id: row.ClaimID})\n",
    "    merge (ap:Physician{id: row.AttendingPhysician})\n",
    "    merge (n)-[:HAS_ATTENDING]->(ap)                                                   \n",
    "''', params = {'data': attend.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876efbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add operating physicians\n",
    "operating = data[['ClaimID','OperatingPhysician']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (n:Claim{id: row.ClaimID})\n",
    "    merge (ap:Physician{id: row.OperatingPhysician})\n",
    "    merge (n)-[:HAS_OPERATING]->(ap)                                               \n",
    "''', params = {'data': operating.to_dict('records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d988df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other physicians\n",
    "other = data[['ClaimID','OtherPhysician']].dropna()\n",
    "\n",
    "gds.run_cypher(''' \n",
    "    unwind $data as row\n",
    "    match (n:Claim{id: row.ClaimID})\n",
    "    merge (ap:Physician{id: row.OtherPhysician})\n",
    "    merge (n)-[:HAS_OTHER]->(ap)                                                    \n",
    "''', params = {'data': other.to_dict('records')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b441cf8",
   "metadata": {},
   "source": [
    "This marks the end of data loading here is the final schema of the data. To see this in the sandbox execute: CALL db.schema.visualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dc272d72320a1930e36722e023630059a17b3b76c58b0a8e1252edca3683d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
